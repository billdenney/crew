---
title: "Specification"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Specification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(crew)
```

The `crew` package consists of `R6` classes. Each object of class `crew` contains an object of class `store` and a list of objects of class `worker`. The `crew`, `store`, and `worker` classes have inheritance hierarchies. Each parent class is an abstract class with a `validate()` method to ensure the concrete instantiable subclasses define all the required methods and fields. Unless ellipsis (`...`) is an argument, all formal arguments of subclass methods must be the same as the arguments of the parent class (but default values can be different).

# worker

A `worker` object encapsulates a worker: a local process, cluster process, or cloud process that accepts and runs work that the crew dispatches.

Inheritance hierarchy so far:

```
├── worker
│   ├── worker_callr
│   └── worker_future
```

Other subclasses will run on cloud services like AWS Batch.

Instantiable concrete subclasses:

* `"worker_callr"`: worker that runs in a `callr::r_bg()` process.
* `"worker_future"`: worker that runs in a `future`.

Required fields:

* `name`: name of the worker.
* `crew`: the `crew` object of the crew it belongs to.
* `timeout`: seconds to idle before the worker times out.
* `wait_input`: seconds to wait between polling for input (a new job).
* `tags`: a character vector, optionally containing user-defined tags to identify a subset of eligible heterogeneous workers for submitting and receiving jobs.
* `assigned`: whether the worker is currently assigned a job.

Required methods:

* `up()`: check whether the worker is running.
* `launch()`: start the worker loop if it not already running.
* `sendable()`: whether the worker is available to accept a new job.
* `send()`: send a job to a worker through the data store and make sure the worker is launched. Errors if the worker is busy (i.e. if `sendable()` returns `FALSE`).
* `receivable()`: whether the worker is done with its current job and is waiting for the crew to read the output data and free the worker to do another job.
* `receive()`: receive job output from the worker. Assumes the worker is receivable.
* `clear()`: remove input and output files for the worker.
* `shutdown()`: send a special job that gracefully shuts down the worker.
* `tagged()`: check if a worker has one or more tags in a given set.
* `stuck()`: check if the worker is stuck (down, not sendable, and not receivable).
* `restart()`: relaunch the worker if it is stuck.
* `validate()`: check for errors in the fields and methods.

New worker subclasses must supply these two methods:

* `launch()`: check if a worker is already up. If it is, return. Then, launch the worker and wait for the worker to be up before returning. Function `crew_wait()`, method `up()`, and worker fields `timeout` and `wait` can help with this. When launched, the worker should run a worker loop such as `crew_worker_loop()` which monitors the data store for jobs and times out when appropriate. Always return `NULL` invisibly on success.
* `up()`: check if a worker is running. This method should make use of the backend technology.

# crew

A `crew` object manages a group of workers. End users can send jobs and receive output through the `crew` object directly without having to interface with individual workers. This class may need to be refactored into backend-specific sub-classes, depending on the need. For example, `receivable()` for local `callr` workers can poll the processes one by one, but for the cloud this would submit too many API requests, and it would be better to poll all the workers at once by listing the first page of job output files in the data store.

Required fields:

* `name`: name of the crew object.
* `store`: data store object.
* `worker_classes`: list of `R6` class definitions to construct workers.
* `workers`: list of worker objects.

Methods:

* `recruit()`: create worker objects from one or more worker definitions. Does not actually launch the new worker objects.
* `launch()`: call the `launch()` method of each worker. Assumes worker `launch()` is idempotent so no worker is re-launched if it is already up.
* `sendable()`: whether any worker is available to accept a new job.
* `send()`: find an appropriate worker for the job and call its `send()` method on the job.
* `receivable()`: whether any worker is done with its current job and is waiting for the crew to read the output data and free the worker to do another job.
* `receive()`: receive job output from the first detected receivable worker. Assumes there exists a receivable worker in the crew.
* `clear()`: remove input and output files one or more workers.
* `shutdown()`: shut down one or more workers. Workers must be sendable if the worker shutdown method uses `send()`.
* `dismiss()`: delete one or more worker objects from the crew. Dismissed workers must be down and sendable, so not all requested dismissals actually happen.
* `restart()`: relaunch stuck workers.
* `validate()`: check for errors in the fields and methods.

# store

A `store` object manages files on a file system that the workers and the crew both can access. Files may exist locally or on the cloud, depending on the subclass. The directory structure of a data store has a single root folder and sub-directories `input/` and `output/`. The former contains instructions and data for submitted jobs, and the latter contains job output written by the workers. In both cases, there is at most one file per worker, with the base name equal to the worker name. That way, to check if a remote worker completed a job successfully, a worker object can simply check if the `output/` file exists for the job currently running. (Although a separate backend-specific mechanism is needed in order to detect crashed workers.)

Inheritance hierarchy:

```
├── store
│   └── store_local
```

The `"store_local"` subclass is the only instantiable sub-class built directly into `crew`. Other packages that depend on `crew` will implement other stores that use AWS/GCP buckets instead of local files.

Required fields:

* `dir_root`: directory or prefix of the root of the store file system.
* `dir_input`: directory or prefix of the input files where jobs are submitted to.
* `dir_output`: directory or prefix where workers save the output from their jobs.

Required methods:

* `path_input()`: return the job input file path of a worker.
* `path_output()`: return the job output file path of a worker.
* `read_input()`: read a job's input file.
* `read_output()`: read a job's output file.
* `write_input()`: write a job's input file.
* `write_output()`: write a job's output file.
* `exists_input()`: check if a job's input file exists.
* `exists_output()`: check if a job's output file exists.
* `delete_input()`: delete a job's input file.
* `delete_output()`: delete a job's output file.
* `destroy()`: delete all the files of the store.
* `marshal()`: represent the store object as a character string of length 1 for efficient transport to the worker event loop. `eval(parse(text = store$marshal()))` should reconstruct the store.
* `validate()`: check for errors in the fields and methods.

Subclasses must supply backend-specific versions of all the above methods except `path_input()` and `path_output()`.
